Hinge Dating App Automation Bot - Development Outline

Current Focus:
- Testing and Validation:
  * Run the program and collect screenshots
  * Validate joke generation quality and relevance
  * Verify prompt/response extraction from screenshots
  * Test OCR accuracy for prompt/response detection
  * Monitor fuzzy matching success rate
  * Document any issues or improvements needed

1. Profile Loading and Initial Screenshot Capture:
   Goals:
   - Load the profile
   - Take full-screen screenshots while scrolling
   - Ensure complete profile coverage

   Currently Implemented:
   1. Profile Loading:
      * Connect to device via ADB
      * Get screen resolution
      * Calculate scroll parameters
   
   2. Screenshot Capture:
      * Initial screenshot at top
      * 8 scrolls with screenshots
      * Save as profile_{count}_part{i}.png
      * OCR processing with pytesseract
      * Visual debugging overlays for each screenshot
      * Color-coded visualization of text elements

   Left to Do:
   - Implement adaptive timing based on device performance
   - Add screenshot quality verification
   - Create OCR retry mechanism with different PSM modes

2. Joke Generation:
   Goals:
   - Process screenshots and context files for joke generation
   - Generate appropriate joke and target prompt
   - Ensure contextual relevance using provided databases

   Currently Implemented:
   1. Context Files:
      * format.txt: Profile structure guide
      * prompts.txt: Available prompts database
      * captions.txt: Photo captions database
   
   2. AI Integration:
      * System prompt with structural information
      * User prompt for specific analysis
      * Returns JSON with prompt, response, and joke
      * Confidence scoring for matches

   Expected Output Structure:
   {
     "prompt": "The exact prompt text to match",
     "response": "The user's response to the prompt",
     "joke": "The generated joke"
   }

3. Prompt Location and Response:
   Goals:
   - Find target prompt on screen
   - Input generated response
   - Send response
   - Create clear visual debugging for text detection
   - Show hierarchical text organization
   - Make OCR results easily reviewable

   Currently Implemented:
   1. Fuzzy Prompt Matching:
      * Input: Target prompt and response text from joke generator
      * Process:
        - Extract all text from current screen using OCR
        - For each potential match:
          a) Try substring match (needle in haystack)
          b) Try reverse substring match (haystack in needle)
          c) Use ratio-based fuzzy matching with difflib
        - Select best match above threshold (0.8)
      * Output:
        - Coordinates of matched element (prompt or response)
        - Confidence score
        - Matched text for verification

   2. Response Input:
      * Verify prompt/response match before proceeding
      * Double-click matched element location
      * Type joke character by character with 100ms delay
      * Send response
      * Fallback to center image tap if no match found

   3. OCR Visualization:
      * Text Box Visualization:
        - Draw gray rectangles around each detected text box
        - Include the actual text content inside each box
        - Box coordinates from pytesseract OCR output
        - Text color matches box outline for clarity
      
      * Line Grouping Visualization:
        - Group text boxes into lines based on vertical alignment
        - Draw red rectangles around each line
        - Line boundaries calculated from contained boxes
        - Ensures all text boxes in a line are fully enclosed
      
      * Paragraph Visualization:
        - Group lines into paragraphs based on spacing
        - Draw green rectangles around each paragraph
        - Paragraph boundaries calculated from contained lines
        - Includes all text boxes and lines in the group
      
      * Visual Debugging Features:
        - Save visualizations for each processing stage:
          * Original screenshot with overlays
          * Separate visualization for each scroll
          * Naming convention: profile_{count}_visual_{part}.png
        - Color coding:
          * Gray: Individual text boxes
          * Red: Line groupings
          * Green: Paragraph boundaries
        - Overlay transparency for readability
        - Text labels for content verification
      
      * Implementation Details:
        - Using PIL (Python Imaging Library) for drawing
        - ImageDraw module for shapes and text
        - Original screenshot as base layer
        - Overlay elements drawn in sequence:
          1. Text boxes (gray)
          2. Line groupings (red)
          3. Paragraph boundaries (green)
        - Text content drawn last for visibility
        - Automatic path generation for saving

   Left to Do:
   - Add real-time visualization for debugging:
     * Show box grouping process
     * Display confidence scores
     * Highlight problematic detections
   - Implement comprehensive error handling:
     * Handle multiple potential matches
     * Handle low confidence matches
     * Retry with different scroll positions
     * Fall back to exact matching if needed
   - Enhance OCR Visualization:
     * Add confidence score visualization
     * Implement layer toggling
     * Add zoom functionality for detailed inspection
     * Create comparison view between original and processed
     * Add metrics overlay (OCR confidence, match scores)

4. Error Handling:
   Goals:
   - Recover from failed operations
   - Maintain bot operation
   - Track and report issues

   Currently Implemented:
   1. Basic Error Handling:
      * OCR failure detection
      * API error handling
      * Input verification
      * Fallback mechanisms for no matches
   
   2. Recovery:
      * Retry mechanisms for text input
      * Profile skipping on critical failures
      * State management for profile processing

   Left to Do:
   - Implement comprehensive logging system
   - Add detailed error recovery strategies
   - Handle prompt matching failures with more granularity
   - Add performance metrics tracking